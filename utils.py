import os
import re
import time
import hashlib
from urllib.parse import urlparse, urljoin
import requests
from PIL import Image
import io
import json
from bs4 import NavigableString, Tag

def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = ['downloads', 'downloads/images', 'temp', 'templates', 'styles']
    for directory in directories:
        os.makedirs(directory, exist_ok=True)

def clean_filename(filename):
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
    return re.sub(r'[<>:"/\\|?*]', '_', filename)

def generate_filename_from_url(url, extension='.jpg'):
    """ä»URLç”Ÿæˆæ–‡ä»¶å"""
    parsed = urlparse(url)
    filename = os.path.basename(parsed.path)
    if not filename or '.' not in filename:
        filename = hashlib.md5(url.encode()).hexdigest()[:8] + extension
    return clean_filename(filename)

def download_image(url, save_path, headers=None):
    """ä¸‹è½½å›¾ç‰‡"""
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # ä¿å­˜å›¾ç‰‡
        with open(save_path, 'wb') as f:
            f.write(response.content)
        
        # ä¼˜åŒ–å›¾ç‰‡å¤§å°
        optimize_image(save_path)
        
        return True
    except Exception as e:
        print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ {url}: {e}")
        return False

def optimize_image(image_path):
    """ä¼˜åŒ–å›¾ç‰‡å¤§å°å’Œè´¨é‡"""
    try:
        with Image.open(image_path) as img:
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # è°ƒæ•´å›¾ç‰‡å¤§å°
            if max(img.size) > 2048:
                img.thumbnail((2048, 2048), Image.Resampling.LANCZOS)
            
            # ä¿å­˜ä¼˜åŒ–åçš„å›¾ç‰‡
            img.save(image_path, 'JPEG', quality=85, optimize=True)
    except Exception as e:
        print(f"ä¼˜åŒ–å›¾ç‰‡å¤±è´¥ {image_path}: {e}")

def extract_question_answer_ids(url):
    """ä»çŸ¥ä¹URLä¸­æå–é—®é¢˜IDå’Œå›ç­”ID"""
    pattern = r'/question/(\d+)/answer/(\d+)'
    match = re.search(pattern, url)
    if match:
        return match.group(1), match.group(2)
    return None, None

def get_timestamp():
    """è·å–å½“å‰æ—¶é—´æˆ³ï¼Œæ ¼å¼ï¼š2025-07-26ï¼ˆåªä¿ç•™æ—¥æœŸï¼‰"""
    return time.strftime("%Y-%m-%d")

def load_cookies_from_json(cookie_file):
    """ä»JSONæ–‡ä»¶åŠ è½½cookies"""
    try:
        with open(cookie_file, 'r', encoding='utf-8') as f:
            cookies = json.load(f)
        
        if isinstance(cookies, dict):
            print(f"âœ… æˆåŠŸåŠ è½½ {len(cookies)} ä¸ªcookies")
            return cookies
        else:
            print("âŒ cookiesæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œåº”è¯¥æ˜¯JSONå¯¹è±¡æ ¼å¼")
            return {}
            
    except json.JSONDecodeError as e:
        print(f"âŒ JSONæ ¼å¼é”™è¯¯: {e}")
        return {}
    except Exception as e:
        print(f"âŒ åŠ è½½cookieså¤±è´¥: {e}")
        return {} 

def flatten_rich_text(element):
    """
    é€’å½’å¤„ç†çŸ¥ä¹å¯Œæ–‡æœ¬ï¼Œä¿æŒå›¾æ–‡é¡ºåºå’Œæ®µè½ç»“æ„ã€‚
    ä¿ç•™å›¾ç‰‡æ ‡ç­¾å’ŒåŸºæœ¬HTMLç»“æ„ï¼Œæ¸…ç†ä¸å¿…è¦çš„åµŒå¥—æ ‡ç­¾ã€‚
    """
    if isinstance(element, NavigableString):
        return str(element)
    elif isinstance(element, Tag):
        if element.name == 'img':
            # ä¿ç•™å›¾ç‰‡æ ‡ç­¾ï¼Œä¿æŒåŸæœ‰å±æ€§
            attrs = []
            for attr in ['src', 'data-src', 'data-original', 'data-actualsrc', 'alt', 'class']:
                if element.has_attr(attr):
                    attrs.append(f'{attr}="{element[attr]}"')
            return f'<img {" ".join(attrs)} />'
        elif element.name in ['br']:
            return '<br>'
        elif element.name in ['p', 'li', 'blockquote', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            # æ®µè½/åˆ—è¡¨/å¼•ç”¨/æ ‡é¢˜ï¼Œé€’å½’å¤„ç†å†…å®¹å¹¶ä¿æŒæ ‡ç­¾ç»“æ„
            inner_content = ''.join([flatten_rich_text(child) for child in element.children])
            if inner_content.strip():
                return f'<{element.name}>{inner_content.strip()}</{element.name}>'
            return ''
        elif element.name in ['ul', 'ol']:
            # åˆ—è¡¨ï¼Œä¿æŒç»“æ„
            list_items = []
            for li in element.find_all('li', recursive=False):
                li_content = ''.join([flatten_rich_text(child) for child in li.children])
                if li_content.strip():
                    list_items.append(f'<li>{li_content.strip()}</li>')
            if list_items:
                return f'<{element.name}>{"".join(list_items)}</{element.name}>'
            return ''
        elif element.name in ['span', 'a', 'b', 'strong', 'em', 'u', 'sup', 'sub']:
            # å†…è”æ ‡ç­¾ï¼Œé€’å½’å¤„ç†å†…å®¹ï¼Œä¿æŒæ ‡ç­¾ç»“æ„
            inner_content = ''.join([flatten_rich_text(child) for child in element.children])
            if inner_content.strip():
                return f'<{element.name}>{inner_content.strip()}</{element.name}>'
            return inner_content
        elif element.name == 'svg':
            # svgä¸€èˆ¬æ˜¯iconï¼Œç”¨ç©ºæ ¼ä»£æ›¿
            return " "
        elif element.name == 'div':
            # divæ ‡ç­¾ï¼Œåªå¤„ç†å†…å®¹ï¼Œä¸ä¿ç•™divæ ‡ç­¾
            return ''.join([flatten_rich_text(child) for child in element.children])
        else:
            # å…¶ä»–æ ‡ç­¾é€’å½’å¤„ç†
            return ''.join([flatten_rich_text(child) for child in element.children])
    return str(element)

def process_content(self, content_elem):
    """
    å¤„ç†çŸ¥ä¹å†…å®¹ï¼Œä¿ç•™å›¾ç‰‡å’Œæ®µè½ç»“æ„ï¼Œçƒ­é—¨è¯ä¸æ¢è¡Œ
    """
    content_html = ""
    images = []
    try:
        print("ğŸ” å¼€å§‹å¤„ç†å†…å®¹...")
        # é€’å½’å¤„ç†æ•´ä¸ªå†…å®¹åŒºåŸŸ
        content_html = flatten_rich_text(content_elem)
        # æå–å›¾ç‰‡
        for img in content_elem.find_all('img'):
            img_data = self.process_image(img)
            if img_data:
                images.append(img_data)
        print(f"âœ… å†…å®¹å¤„ç†å®Œæˆ: {len(content_html)}å­—ç¬¦, {len(images)}å¼ å›¾ç‰‡")
    except Exception as e:
        print(f"âŒ å¤„ç†å†…å®¹å¤±è´¥: {e}")
    return content_html, images 